import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import Standardscale
from sklearn.linear_model import LogisticRegression 
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier



df=pd.read_csv('')
df.head()
df.info()
df.describe()
df.shape
df.isnull().sum()
df[index number].value_counts()
df.groupby(index number).mean()
X= df.drop(column=60,axis=1)
Y=df[60]
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1,Stratify=Y,random_state=1)
X_train.shape,X_test.shape
model training:
model = LogisticRegression()
model.fit(X_train,Y_train)
model evaluation 
accuracy on training data
pre=model.predict(x_train)
training_data_accuracy=accuracy_score(pre,Y_train)

model=Randomforestclassifier()
model.fit(X_test,Y_test)
pre=model.predict(X_test)
acc=accuracy_score(pre,Y_test)

input_data=()
i=np.asarray(input_data)
i_reshape=i.reshape(1,-1)
prediction=model.predict(i_reshape)
print(prediction)
if(prediction[0] =='R')
  print()
else:
print()



# Correlation matrix to measure linear relationships
correlation_matrix = data[['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 
'acceleration']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.show()
# Boxplot to visualize the distribution of 'mpg' based on 'origin'
sns.boxplot(x='origin', y='mpg', data=data)
plt.show()



# Countplot for 'cylinders' to observe the distribution of cylinder values
sns.countplot(x='cylinders', data=data)
plt.show()
# Distribution plot for 'mpg'
sns.histplot(data['mpg'], kde=True, bins=20)
plt.show()

imputer=KNNImputer(n_neighbors=2)
data['mpg']=imputer.fit_transform(data['mpg'])


correlation= df.corr()
plot=plt.figure(figsize=(10,10))
sns.heatmap(correlation,cbar=True,square=true,annot=true,annot_kws=('size':8),cmap=true,fmt='.1f')
from sklearn.metrics import confusion_matrix 
y_pred = model.predict(x_test) 
cm = confusion_matrix(y_test, y_pred) 
cm
sns.heatmap(cm,annot=True)


mean and mode 

df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].mean())
# fill the missing values for categorical terms - mode
df['Gender'] = df["Gender"].fillna(df['Gender'].mode()[0])
log transformation
df['ApplicantIncomeLog'] = np.log(df['ApplicantIncome']+1)
sns.distplot(df["ApplicantIncomeLog"])

clf=svm.SVC(kernel='linear',c=1.0)
from sklearn.naive_bayes_algorithm import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)




import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score

# Load Iris dataset
iris = load_iris()
df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])

# Visualize the data distributions for each species
sns.pairplot(df, hue='target', diag_kind='kde')
plt.show()

# Display correlation heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# Display histograms for each numerical column
plt.figure(figsize=(15, 10))
for i, column in enumerate(df.columns[:-1], 1):
    plt.subplot(2, 2, i)
    df[column].hist()
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

# Display basic information about the dataset
print("Dataset Information:")
print(df.info())

# Step 3: Display the first few rows of the dataset
print("\nFirst few rows of the dataset:")
print(df.head())
print("Summary Statistics:")
print(df.describe())
print("\nMissing Values:")
print(df.isnull().sum())

# Check data types
print("\nData Types:")
print(df.dtypes)

print("\nCorrelation Matrix:")
print(df.corr())

# Load Iris dataset using seaborn
iris_df = sns.load_dataset("iris")

# Display basic information about the dataset
print(iris_df.info())

# Visualize the distribution of features using box plots
plt.figure(figsize=(10, 6))
sns.boxplot(data=iris_df.drop(columns='species'))
plt.title("Boxplot of Iris Features")
plt.show()

# Split data into features and target variable
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Perform PCA
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Feature selection techniques
feature_selection_techniques = {
    'SelectKBest': SelectKBest(score_func=f_classif, k=2),
    'PCA': PCA(n_components=2)
}

# Empty dictionary to store results
results = {}

# Iterate over feature selection techniques
for fs_name, fs_method in feature_selection_techniques.items():
    if fs_name == 'PCA':
        X_train_selected = X_train_pca
        X_test_selected = X_test_pca
    else:
        X_train_selected = fs_method.fit_transform(X_train_scaled, y_train)
        X_test_selected = fs_method.transform(X_test_scaled)

    # Initialize dictionary to store results
    cv_results = {
        'Naive Bayes': {},
        'SVM': {},
        'Random Forest': {}
    }

    # Naive Bayes classifier
    nb_classifier = GaussianNB()
    nb_scores = cross_val_score(nb_classifier, X_train_selected, y_train, cv=5, scoring='accuracy')
    nb_accuracy = np.mean(nb_scores)
    cv_results['Naive Bayes']['Cross-validation Accuracy'] = nb_accuracy

    nb_classifier.fit(X_train_selected, y_train)
    nb_predictions = nb_classifier.predict(X_test_selected)
    nb_accuracy_test = accuracy_score(y_test, nb_predictions)
    nb_f1 = f1_score(y_test, nb_predictions, average='weighted')
    nb_recall = recall_score(y_test, nb_predictions, average='weighted')
    nb_precision = precision_score(y_test, nb_predictions, average='weighted')
    cv_results['Naive Bayes'].update({
        'Accuracy': nb_accuracy_test,
        'F1 Score': nb_f1,
        'Recall': nb_recall,
        'Precision': nb_precision
    })

    # Support Vector Machine (SVM) classifier
    svm_classifier = SVC(kernel='linear')
    svm_scores = cross_val_score(svm_classifier, X_train_selected, y_train, cv=5, scoring='accuracy')
    svm_accuracy = np.mean(svm_scores)
    cv_results['SVM']['Cross-validation Accuracy'] = svm_accuracy

    svm_classifier.fit(X_train_selected, y_train)
    svm_predictions = svm_classifier.predict(X_test_selected)
    svm_accuracy_test = accuracy_score(y_test, svm_predictions)
    svm_f1 = f1_score(y_test, svm_predictions, average='weighted')
    svm_recall = recall_score(y_test, svm_predictions, average='weighted')
    svm_precision = precision_score(y_test, svm_predictions, average='weighted')
    cv_results['SVM'].update({
        'Accuracy': svm_accuracy_test,
        'F1 Score': svm_f1,
        'Recall': svm_recall,
        'Precision': svm_precision
    })

    # Random Forest classifier
    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_scores = cross_val_score(rf_classifier, X_train_selected, y_train, cv=5, scoring='accuracy')
    rf_accuracy = np.mean(rf_scores)
    cv_results['Random Forest']['Cross-validation Accuracy'] = rf_accuracy

    rf_classifier.fit(X_train_selected, y_train)
    rf_predictions = rf_classifier.predict(X_test_selected)
    rf_accuracy_test = accuracy_score(y_test, rf_predictions)
    rf_f1 = f1_score(y_test, rf_predictions, average='weighted')
    rf_recall = recall_score(y_test, rf_predictions, average='weighted')
    rf_precision = precision_score(y_test, rf_predictions, average='weighted')
    cv_results['Random Forest'].update({
        'Accuracy': rf_accuracy_test,
        'F1 Score': rf_f1,
        'Recall': rf_recall,
        'Precision': rf_precision
    })

    results[fs_name] = cv_results

# Convert results to DataFrame
results_df = pd.DataFrame.from_dict({(i, j): results[i][j] for i in results.keys() for j in results[i].keys()}, orient='index')

# Display results
print("Results with Cross-validation and Evaluation Metrics:")
print(results_df)

# Hyperparameter tuning for SVM
svm_param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf']}
svm_grid_search = GridSearchCV(SVC(), svm_param_grid, refit=True, verbose=2)
svm_grid_search.fit(X_train_scaled, y_train)

# Print best hyperparameters for SVM
print("Best Hyperparameters for SVM:", svm_grid_search.best_params_)

best_svm_model = svm_grid_search.best_estimator_
best_svm_predictions = best_svm_model.predict(X_test_scaled)

# Hyperparameter tuning for Random Forest
rf_param_grid = {'n_estimators': [10, 50, 100, 200], 'max_depth': [None, 10, 20, 30]}
rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, refit=True, verbose=2)
rf_grid_search.fit(X_train_scaled, y_train)

# Print best hyperparameters for Random Forest
print("Best Hyperparameters for Random Forest:", rf_grid_search.best_params_)

best_rf_model = rf_grid_search.best_estimator_
best_rf_predictions = best_rf_model.predict(X_test_scaled)

# Store best hyperparameters
best_svm_params = svm_grid_search.best_params_
best_rf_params = rf_grid_search.best_params_

# Calculate metrics for best SVM and Random Forest models
best_svm_accuracy = accuracy_score(y_test, best_svm_predictions)
best_svm_f1 = f1_score(y_test, best_svm_predictions, average='weighted')
best_svm_recall = recall_score(y_test, best_svm_predictions, average='weighted')
best_svm_precision = precision_score(y_test, best_svm_predictions, average='weighted')

best_rf_accuracy = accuracy_score(y_test, best_rf_predictions)
best_rf_f1 = f1_score(y_test, best_rf_predictions, average='weighted')
best_rf_recall = recall_score(y_test, best_rf_predictions, average='weighted')
best_rf_precision = precision_score(y_test, best_rf_predictions, average='weighted')

# Plotting confusion matrices
def plot_confusion_matrices(results, X_test, y_test, target_names):
    for clf_name, clf_results in results.items():
        plt.figure()
        clf_predictions = clf_results['Best Model'].predict(X_test)
        cm = confusion_matrix(y_test, clf_predictions)
        sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", cbar=False, xticklabels=target_names, yticklabels=target_names)
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title(f"{clf_name} Confusion Matrix")

# Plot confusion matrices
plot_confusion_matrices({'SVM': {'Best Model': best_svm_model}, 'Random Forest': {'Best Model': best_rf_model}}, X_test_scaled, y_test, iris.target_names)

plt.show()
idhu nee anupcha code dhaimport pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score

# Load Iris dataset
iris = load_iris()
df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])

# Visualize the data distributions for each species
sns.pairplot(df, hue='target', diag_kind='kde')
plt.show()

# Display correlation heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# Display histograms for each numerical column
plt.figure(figsize=(15, 10))
for i, column in enumerate(df.columns[:-1], 1):
    plt.subplot(2, 2, i)
    df[column].hist()
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

# Display basic information about the dataset
print("Dataset Information:")
print(df.info())

# Step 3: Display the first few rows of the dataset
print("\nFirst few rows of the dataset:")
print(df.head())
print("Summary Statistics:")
print(df.describe())
print("\nMissing Values:")
print(df.isnull().sum())

# Check data types
print("\nData Types:")
print(df.dtypes)

print("\nCorrelation Matrix:")
print(df.corr())

# Load Iris dataset using seaborn
iris_df = sns.load_dataset("iris")

# Display basic information about the dataset
print(iris_df.info())

# Visualize the distribution of features using box plots
plt.figure(figsize=(10, 6))
sns.boxplot(data=iris_df.drop(columns='species'))
plt.title("Boxplot of Iris Features")
plt.show()

# Split data into features and target variable
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Perform PCA
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Feature selection techniques
feature_selection_techniques = {
    'SelectKBest': SelectKBest(score_func=f_classif, k=2),
    'PCA': PCA(n_components=2)
}

# Empty dictionary to store results
results = {}

# Iterate over feature selection techniques
for fs_name, fs_method in feature_selection_techniques.items():
    if fs_name == 'PCA':
        X_train_selected = X_train_pca
        X_test_selected = X_test_pca
    else:
        X_train_selected = fs_method.fit_transform(X_train_scaled, y_train)
        X_test_selected = fs_method.transform(X_test_scaled)

    # Initialize dictionary to store results
    cv_results = {
        'Naive Bayes': {},
        'SVM': {},
        'Random Forest': {}
    }

    # Naive Bayes classifier
    nb_classifier = GaussianNB()
    nb_scores = cross_val_score(nb_classifier, X_train_selected, y_train, cv=5, scoring='accuracy')
    nb_accuracy = np.mean(nb_scores)
    cv_results['Naive Bayes']['Cross-validation Accuracy'] = nb_accuracy

    nb_classifier.fit(X_train_selected, y_train)
    nb_predictions = nb_classifier.predict(X_test_selected)
    nb_accuracy_test = accuracy_score(y_test, nb_predictions)
    nb_f1 = f1_score(y_test, nb_predictions, average='weighted')
    nb_recall = recall_score(y_test, nb_predictions, average='weighted')
    nb_precision = precision_score(y_test, nb_predictions, average='weighted')
    cv_results['Naive Bayes'].update({
        'Accuracy': nb_accuracy_test,
        'F1 Score': nb_f1,
        'Recall': nb_recall,
        'Precision': nb_precision
    })

    # Support Vector Machine (SVM) classifier
    svm_classifier = SVC(kernel='linear')
    svm_scores = cross_val_score(svm_classifier, X_train_selected, y_train, cv=5, scoring='accuracy')
    svm_accuracy = np.mean(svm_scores)
    cv_results['SVM']['Cross-validation Accuracy'] = svm_accuracy

    svm_classifier.fit(X_train_selected, y_train)
    svm_predictions = svm_classifier.predict(X_test_selected)
    svm_accuracy_test = accuracy_score(y_test, svm_predictions)
    svm_f1 = f1_score(y_test, svm_predictions, average='weighted')
    svm_recall = recall_score(y_test, svm_predictions, average='weighted')
    svm_precision = precision_score(y_test, svm_predictions, average='weighted')
    cv_results['SVM'].update({
        'Accuracy': svm_accuracy_test,
        'F1 Score': svm_f1,
        'Recall': svm_recall,
        'Precision': svm_precision
    })

    # Random Forest classifier
    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_scores = cross_val_score(rf_classifier, X_train_selected, y_train, cv=5, scoring='accuracy')
    rf_accuracy = np.mean(rf_scores)
    cv_results['Random Forest']['Cross-validation Accuracy'] = rf_accuracy

    rf_classifier.fit(X_train_selected, y_train)
    rf_predictions = rf_classifier.predict(X_test_selected)
    rf_accuracy_test = accuracy_score(y_test, rf_predictions)
    rf_f1 = f1_score(y_test, rf_predictions, average='weighted')
    rf_recall = recall_score(y_test, rf_predictions, average='weighted')
    rf_precision = precision_score(y_test, rf_predictions, average='weighted')
    cv_results['Random Forest'].update({
        'Accuracy': rf_accuracy_test,
        'F1 Score': rf_f1,
        'Recall': rf_recall,
        'Precision': rf_precision
    })

    results[fs_name] = cv_results

# Convert results to DataFrame
results_df = pd.DataFrame.from_dict({(i, j): results[i][j] for i in results.keys() for j in results[i].keys()}, orient='index')

# Display results
print("Results with Cross-validation and Evaluation Metrics:")
print(results_df)

# Hyperparameter tuning for SVM
svm_param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf']}
svm_grid_search = GridSearchCV(SVC(), svm_param_grid, refit=True, verbose=2)
svm_grid_search.fit(X_train_scaled, y_train)

# Print best hyperparameters for SVM
print("Best Hyperparameters for SVM:", svm_grid_search.best_params_)

best_svm_model = svm_grid_search.best_estimator_
best_svm_predictions = best_svm_model.predict(X_test_scaled)

# Hyperparameter tuning for Random Forest
rf_param_grid = {'n_estimators': [10, 50, 100, 200], 'max_depth': [None, 10, 20, 30]}
rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, refit=True, verbose=2)
rf_grid_search.fit(X_train_scaled, y_train)

# Print best hyperparameters for Random Forest
print("Best Hyperparameters for Random Forest:", rf_grid_search.best_params_)

best_rf_model = rf_grid_search.best_estimator_
best_rf_predictions = best_rf_model.predict(X_test_scaled)

# Store best hyperparameters
best_svm_params = svm_grid_search.best_params_
best_rf_params = rf_grid_search.best_params_

# Calculate metrics for best SVM and Random Forest models
best_svm_accuracy = accuracy_score(y_test, best_svm_predictions)
best_svm_f1 = f1_score(y_test, best_svm_predictions, average='weighted')
best_svm_recall = recall_score(y_test, best_svm_predictions, average='weighted')
best_svm_precision = precision_score(y_test, best_svm_predictions, average='weighted')

best_rf_accuracy = accuracy_score(y_test, best_rf_predictions)
best_rf_f1 = f1_score(y_test, best_rf_predictions, average='weighted')
best_rf_recall = recall_score(y_test, best_rf_predictions, average='weighted')
best_rf_precision = precision_score(y_test, best_rf_predictions, average='weighted')

# Plotting confusion matrices
def plot_confusion_matrices(results, X_test, y_test, target_names):
    for clf_name, clf_results in results.items():
        plt.figure()
        clf_predictions = clf_results['Best Model'].predict(X_test)
        cm = confusion_matrix(y_test, clf_predictions)
        sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", cbar=False, xticklabels=target_names, yticklabels=target_names)
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title(f"{clf_name} Confusion Matrix")

# Plot confusion matrices
plot_confusion_matrices({'SVM': {'Best Model': best_svm_model}, 'Random Forest': {'Best Model': best_rf_model}}, X_test_scaled, y_test, iris.target_names)

plt.show()
idhu nee anupcha code dha



